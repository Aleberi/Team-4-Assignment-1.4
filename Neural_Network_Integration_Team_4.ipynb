{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Enabling GPU in Google Colab**"
      ],
      "metadata": {
        "id": "SowHKuGHXMzA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sik1IQzuTMq9",
        "outputId": "0681684e-0350-4df8-b1d5-74c7eedd9fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Train the MLP Model**\n"
      ],
      "metadata": {
        "id": "7DxVRzuFXUUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Specifying preprocessing pipeline\n",
        "categorical_columns = ['Ticker']\n",
        "numeric_columns = ['Open', 'Close', 'High', 'Low', 'Adjusted Close', 'Volume']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_columns),\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Defining model pipeline\n",
        "model2 = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('mlp', MLPRegressor(max_iter=500, random_state=42))\n",
        "])\n",
        "\n",
        "# Specifying grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'mlp__hidden_layer_sizes': [(30,30,30), (50,50,50), (50,100,50)],\n",
        "    'mlp__activation': ['tanh', 'relu'],\n",
        "    'mlp__solver': ['sgd', 'adam'],\n",
        "}\n",
        "\n",
        "# Using GridSearchCV to find best hyperparameters\n",
        "grid_search = GridSearchCV(model2, param_grid, cv=5)\n",
        "\n",
        "# Loading the dataset\n",
        "data = pd.read_csv('/top_50_stocks_data_formatted.csv')\n",
        "\n",
        "# Separating features and target\n",
        "X = data[categorical_columns + numeric_columns]\n",
        "y = data['Close']\n",
        "\n",
        "# Splitting data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fitting model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Displaying best parameters\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Making predictions\n",
        "mlp_predictions = grid_search.predict(X_test)\n",
        "\n",
        "# Calculate MSE\n",
        "mse_mlp = mean_squared_error(y_test, mlp_predictions)\n",
        "print(f\"MLP Mean Squared Error: {mse_mlp}\")\n",
        "\n",
        "# Plot actual vs predicted\n",
        "plt.scatter(y_test, mlp_predictions)\n",
        "plt.plot(y_test, y_test, color='r')\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Predicted Prices')\n",
        "plt.title('MLP: Actual vs Predicted Stock Prices')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4d1y3TaXT3T",
        "outputId": "618a93c1-3d7c-4083-bde3-d9b20d4f871f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Train the RNN Model**\n"
      ],
      "metadata": {
        "id": "jQUiYr3kX9eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Preparing data for RNN\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data[['Close']])\n",
        "\n",
        "# Create a function to process data for RNN input\n",
        "def create_rnn_data(data, time_steps=60):\n",
        "    X, y = [], []\n",
        "    for i in range(time_steps, len(data)):\n",
        "        X.append(data[i-time_steps:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_steps = 60\n",
        "X_rnn, y_rnn = create_rnn_data(scaled_data, time_steps)\n",
        "\n",
        "# Reshape data to fit RNN input\n",
        "X_rnn = np.reshape(X_rnn, (X_rnn.shape[0], X_rnn.shape[1], 1))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "split = int(0.8 * len(X_rnn))\n",
        "X_rnn_train, X_rnn_test = X_rnn[:split], X_rnn[split:]\n",
        "y_rnn_train, y_rnn_test = y_rnn[:split], y_rnn[split:]\n",
        "\n",
        "# Build RNN model\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(LSTM(units=50, return_sequences=True, input_shape=(X_rnn_train.shape[1], 1)))\n",
        "model_rnn.add(LSTM(units=50))\n",
        "model_rnn.add(Dense(1))\n",
        "\n",
        "model_rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the RNN model\n",
        "model_rnn.fit(X_rnn_train, y_rnn_train, epochs=100, batch_size=32)\n",
        "\n",
        "# Make predictions\n",
        "rnn_predictions = model_rnn.predict(X_rnn_test)\n",
        "rnn_predictions = scaler.inverse_transform(rnn_predictions)\n",
        "\n",
        "# Calculate MSE\n",
        "mse_rnn = mean_squared_error(y_rnn_test, rnn_predictions)\n",
        "print(f\"RNN Mean Squared Error: {mse_rnn}\")\n",
        "\n",
        "# Plot actual vs predicted\n",
        "plt.scatter(y_rnn_test, rnn_predictions)\n",
        "plt.plot(y_rnn_test, y_rnn_test, color='r')\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Predicted Prices')\n",
        "plt.title('RNN: Actual vs Predicted Stock Prices')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Iq3uQXueXs6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Combine Predictions (Ensemble)**\n"
      ],
      "metadata": {
        "id": "RQBuVLkVYFK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine predictions using simple averaging\n",
        "ensemble_predictions = (mlp_predictions + rnn_predictions.flatten()) / 2\n",
        "\n",
        "# Calculate MSE for ensemble\n",
        "mse_ensemble = mean_squared_error(y_test, ensemble_predictions)\n",
        "print(f\"Ensemble Mean Squared Error: {mse_ensemble}\")\n",
        "\n",
        "# Plot actual vs predicted\n",
        "plt.scatter(y_test, ensemble_predictions)\n",
        "plt.plot(y_test, y_test, color='r')\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Predicted Prices')\n",
        "plt.title('Ensemble: Actual vs Predicted Stock Prices')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N5t7TgBQYJvw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}